/*
 * Copyright (C) 2015 Google Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.imaginecup.ensharp.guardear;

import android.content.Context;
import android.media.MediaCodec;
import android.media.MediaExtractor;
import android.media.MediaFormat;
import android.util.Log;
import android.view.GestureDetector;
import android.view.ScaleGestureDetector;

import java.io.File;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.ShortBuffer;

public class SoundFile {

    private File mInputFile = null;
    // Member variables representing frame data
    private String mFileType;
    private int mFileSize;
    private int mAvgBitRate;  // Average bit rate in kbps.
    private int mChannels;
    private int mNumSamples;  // total number of samples per channel in audio file
    private ByteBuffer mDecodedBytes;  // Raw audio data
    private ShortBuffer mDecodedSamples;  // shared buffer with mDecodedBytes.
    private int mNumFrames;
    private int[] mFrameGains;
    private int[] mFrameLens;
    private int[] mFrameOffsets;

    private int[] mLenByZoomLevel;
    private double[][] mValuesByZoomLevel;
    private double[] mZoomFactorByZoomLevel;
    private int[] mHeightsAtThisZoomLevel;
    private int mZoomLevel;
    private int mNumZoomLevels;
    private int mSampleRate;
    private int mSamplesPerFrame = 1024;
    private int mOffset;
    private int mSelectionStart;
    private int mSelectionEnd;
    private int mPlaybackPos;
    private float mDensity;
    private float mInitialScaleSpan;
    private GestureDetector mGestureDetector;
    private ScaleGestureDetector mScaleGestureDetector;
    private boolean mInitialized;
    private SharedPreferences mPref;
    private Context mContext;
    private String mFileName;
    private String mKeyName;
    private static final int DECIBEL_CONSTANTS = 20;

    // Custom exception for invalid inputs.
    public class InvalidInputException extends Exception {
        // Serial version ID generated by Eclipse.
        private static final long serialVersionUID = -2505698991597837165L;

        public InvalidInputException(String message) {
            super(message);
        }
    }

    // TODO(nfaralli): what is the real list of supported extensions? Is it device dependent?
    public static String[] getSupportedExtensions() {
        return new String[]{"mp3", "wav", "3gpp", "3gp", "amr", "aac", "m4a", "ogg"};
    }

    // Create and return a SoundFile object using the file fileName.
    public void create(String fileName, String keyName, Context context)
            throws java.io.FileNotFoundException,
            java.io.IOException, InvalidInputException {
        // First check that the file exists and that its extension is supported.
        this.mContext = context;
        this.mFileName = fileName;
        this.mKeyName = keyName;
        Log.i("mKeyName", mKeyName);
        mPref = new SharedPreferences(mContext);
        File f = new File(fileName);
        if (!f.exists()) {
            throw new java.io.FileNotFoundException(fileName);
        }
        ReadFile(f);
    }

    // Should be removed when the app will use directly the samples instead of the frames.
    public int getSamplesPerFrame() {
        return 1024;  // just a fixed value here...
    }

    public void ReadFile(File inputFile)
            throws java.io.FileNotFoundException,
            java.io.IOException, InvalidInputException {
        MediaExtractor extractor = new MediaExtractor();
        MediaFormat format = null;
        int i;
        Log.i("ReadFile", "시작");
        mInputFile = inputFile;
        //Log.i("inputFile 값",inputFile.toString());
        String[] components = mInputFile.getPath().split("\\.");
        mFileType = components[components.length - 1];
        //Log.i(" mFileType 값",components[components.length - 1]);
        mFileSize = (int) mInputFile.length();
        extractor.setDataSource(mInputFile.getPath());
        //Log.i("mInputFile.getPath() 값",mInputFile.getPath());
        int numTracks = extractor.getTrackCount();
        // find and select the first audio track present in the file.
        for (i = 0; i < numTracks; i++) {
            format = extractor.getTrackFormat(i);
            if (format.getString(MediaFormat.KEY_MIME).startsWith("audio/")) {
                extractor.selectTrack(i);
                break;
            }
        }
        if (i == numTracks) {
            throw new InvalidInputException("No audio track found in " + mInputFile);
        }
        mChannels = format.getInteger(MediaFormat.KEY_CHANNEL_COUNT);
        mSampleRate = format.getInteger(MediaFormat.KEY_SAMPLE_RATE);
        // Expected total number of samples per channel.
        int expectedNumSamples =
                (int) ((format.getLong(MediaFormat.KEY_DURATION) / 1000000.f) * mSampleRate + 0.5f);

        MediaCodec codec = MediaCodec.createDecoderByType(format.getString(MediaFormat.KEY_MIME));
        codec.configure(format, null, null, 0);
        codec.start();

        int decodedSamplesSize = 0;  // size of the output buffer containing decoded samples.
        byte[] decodedSamples = null;
        ByteBuffer[] inputBuffers = codec.getInputBuffers();
        ByteBuffer[] outputBuffers = codec.getOutputBuffers();
        int sample_size;
        MediaCodec.BufferInfo info = new MediaCodec.BufferInfo();
        long presentation_time;
        int tot_size_read = 0;
        boolean done_reading = false;

        // Set the size of the decoded samples buffer to 1MB (~6sec of a stereo stream at 44.1kHz).
        // For longer streams, the buffer size will be increased later on, calculating a rough
        // estimate of the total size needed to store all the samples in order to resize the buffer
        // only once.
        mDecodedBytes = ByteBuffer.allocate(1 << 20);
        Boolean firstSampleData = true;
        while (true) {
            // read data from file and feed it to the decoder input buffers.
            int inputBufferIndex = codec.dequeueInputBuffer(100);
            if (!done_reading && inputBufferIndex >= 0) {
                sample_size = extractor.readSampleData(inputBuffers[inputBufferIndex], 0);
                if (firstSampleData
                        && format.getString(MediaFormat.KEY_MIME).equals("audio/mp4a-latm")
                        && sample_size == 2) {
                    // For some reasons on some devices (e.g. the Samsung S3) you should not
                    // provide the first two bytes of an AAC stream, otherwise the MediaCodec will
                    // crash. These two bytes do not contain music data but basic info on the
                    // stream (e.g. channel configuration and sampling frequency), and skipping them
                    // seems OK with other devices (MediaCodec has already been configured and
                    // already knows these parameters).
                    extractor.advance();
                    tot_size_read += sample_size;
                } else if (sample_size < 0) {
                    // All samples have been read.
                    codec.queueInputBuffer(
                            inputBufferIndex, 0, 0, -1, MediaCodec.BUFFER_FLAG_END_OF_STREAM);
                    done_reading = true;
                } else {
                    presentation_time = extractor.getSampleTime();
                    codec.queueInputBuffer(inputBufferIndex, 0, sample_size, presentation_time, 0);
                    extractor.advance();
                    tot_size_read += sample_size;
                }
                firstSampleData = false;
            }

            // Get decoded stream from the decoder output buffers.
            int outputBufferIndex = codec.dequeueOutputBuffer(info, 100);
            if (outputBufferIndex >= 0 && info.size > 0) {
                if (decodedSamplesSize < info.size) {
                    decodedSamplesSize = info.size;
                    decodedSamples = new byte[decodedSamplesSize];
                }
                outputBuffers[outputBufferIndex].get(decodedSamples, 0, info.size);
                outputBuffers[outputBufferIndex].clear();
                // Check if buffer is big enough. Resize it if it's too small.
                if (mDecodedBytes.remaining() < info.size) {
                    // Getting a rough estimate of the total size, allocate 20% more, and
                    // make sure to allocate at least 5MB more than the initial size.
                    int position = mDecodedBytes.position();
                    int newSize = (int) ((position * (1.0 * mFileSize / tot_size_read)) * 1.2);
                    if (newSize - position < info.size + 5 * (1 << 20)) {
                        newSize = position + info.size + 5 * (1 << 20);
                    }
                    ByteBuffer newDecodedBytes = null;
                    // Try to allocate memory. If we are OOM, try to run the garbage collector.
                    int retry = 10;
                    while (retry > 0) {
                        try {
                            newDecodedBytes = ByteBuffer.allocate(newSize);
                            break;
                        } catch (OutOfMemoryError oome) {
                            // setting android:largeHeap="true" in <application> seem to help not
                            // reaching this section.
                            retry--;
                        }
                    }
                    if (retry == 0) {
                        // Failed to allocate memory... Stop reading more data and finalize the
                        // instance with the data decoded so far.
                        break;
                    }
                    //ByteBuffer newDecodedBytes = ByteBuffer.allocate(newSize);
                    mDecodedBytes.rewind();
                    newDecodedBytes.put(mDecodedBytes);
                    mDecodedBytes = newDecodedBytes;
                    mDecodedBytes.position(position);
                }
                mDecodedBytes.put(decodedSamples, 0, info.size);
                codec.releaseOutputBuffer(outputBufferIndex, false);
            } else if (outputBufferIndex == MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED) {
                outputBuffers = codec.getOutputBuffers();
            } else if (outputBufferIndex == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {
                // Subsequent data will conform to new format.
                // We could check that codec.getOutputFormat(), which is the new output format,
                // is what we expect.
            }
            if ((info.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0
                    || (mDecodedBytes.position() / (2 * mChannels)) >= expectedNumSamples) {
                // We got all the decoded data from the decoder. Stop here.
                // Theoretically dequeueOutputBuffer(info, ...) should have set info.flags to
                // MediaCodec.BUFFER_FLAG_END_OF_STREAM. However some phones (e.g. Samsung S3)
                // won't do that for some files (e.g. with mono AAC files), in which case subsequent
                // calls to dequeueOutputBuffer may result in the application crashing, without
                // even an exception being thrown... Hence the second check.
                // (for mono AAC files, the S3 will actually double each sample, as if the stream
                // was stereo. The resulting stream is half what it's supposed to be and with a much
                // lower pitch.)
                break;
            }
        }
        mNumSamples = mDecodedBytes.position() / (mChannels * 2);  // One sample = 2 bytes.
        mDecodedBytes.rewind();
        mDecodedBytes.order(ByteOrder.LITTLE_ENDIAN);
        mDecodedSamples = mDecodedBytes.asShortBuffer();
        mAvgBitRate = (int) ((mFileSize * 8) * ((float) mSampleRate / mNumSamples) / 1000);

        extractor.release();
        extractor = null;
        codec.stop();
        codec.release();
        codec = null;

        // Temporary hack to make it work with the old version.
        mNumFrames = mNumSamples / getSamplesPerFrame();
        if (mNumSamples % getSamplesPerFrame() != 0) {
            mNumFrames++;
        }
        mFrameGains = new int[mNumFrames];
        mFrameLens = new int[mNumFrames];
        mFrameOffsets = new int[mNumFrames];
        double[] heights = new double[mNumFrames];
        int j;
        int gain, value;
        int frameLens = (int) ((1000 * mAvgBitRate / 8) *
                ((float) getSamplesPerFrame() / mSampleRate));
        for (i = 0; i < mNumFrames; i++) {
            gain = -1;
            for (j = 0; j < getSamplesPerFrame(); j++) {
                value = 0;
                for (int k = 0; k < mChannels; k++) {
                    if (mDecodedSamples.remaining() > 0) {
                        value += java.lang.Math.abs(mDecodedSamples.get());
                    }
                }
                value /= mChannels;
                if (gain < value) {
                    gain = value;
                }
            }
            heights[i] = gain;
            mFrameGains[i] = (int) Math.sqrt(gain);  // here gain = sqrt(max value of 1st channel)...
            mFrameLens[i] = frameLens;  // totally not accurate...
            mFrameOffsets[i] = (int) (i * (1000 * mAvgBitRate / 8) *  //  = i * frameLens
                    ((float) getSamplesPerFrame() / mSampleRate));
        }
        mDecodedSamples.rewind();
        // DumpSamples();  // Uncomment this line to dump the samples in a TSV file.
        Log.i("ReadFile", "종료");
        computeDoublesForAllZoomLevels(heights);
    }

    public void getAverageHeight() {


    }

    public void computeDoublesForAllZoomLevels(double[] musicHeight) {
        Log.i("computeDoubles", "시작");
        double decibels;
        double[] musicHeights = musicHeight;
        int numFrames = mNumFrames;
        int[] myLenByZoomLevel = new int[5];
        double[] myZoomFactorByZoomLevel = new double[5];
        int myZoomLevel;
        double average = 0.0;
        Log.i("numFrames 값", Integer.toString(numFrames));
        int[] frameGains = mFrameGains;
        double[] smoothedGains = new double[numFrames];
        if (numFrames == 1) {
            smoothedGains[0] = frameGains[0];
        } else if (numFrames == 2) {
            smoothedGains[0] = frameGains[0];
            smoothedGains[1] = frameGains[1];
        } else if (numFrames > 2) {
            smoothedGains[0] = (double) (
                    (frameGains[0] / 2.0) +
                            (frameGains[1] / 2.0));
            average += smoothedGains[0];
            //Log.i("frameGains [" +Integer.toString(0)+"] " + "값",Double.toString(frameGains[0]));
            for (int i = 1; i < numFrames - 1; i++) {
                smoothedGains[i] = (double) (
                        (frameGains[i - 1] / 3.0) +
                                (frameGains[i] / 3.0) +
                                (frameGains[i + 1] / 3.0));
                average += smoothedGains[i];
                //Log.i("frameGains [" +Integer.toString(i)+"] " + "값",Double.toString(frameGains[i    ]));
                //Log.i("smoothedGains [" +Integer.toString(i)+"] " + "값",Double.toString(smoothedGains[i]));
            }
            smoothedGains[numFrames - 1] = (double) (
                    (frameGains[numFrames - 2] / 2.0) +
                            (frameGains[numFrames - 1] / 2.0));
            average += smoothedGains[numFrames - 1];
            //Log.i("덧셈값과 나눌값 : ", Double.toString(average) + " / " + numFrames);
            //Log.i("frameGains [" +Integer.toString(numFrames - 1)+"] " + "값",Double.toString(frameGains[numFrames - 1]));
            //Log.i("smoothedGains [" +Integer.toString(numFrames - 1)+"] " + "값",Double.toString(smoothedGains[numFrames - 1]));
        }

        // Make sure the range is no more than 0 - 255
        double maxGain = 1.0;
        for (int i = 0; i < numFrames; i++) {
            if (smoothedGains[i] > maxGain) {
                maxGain = smoothedGains[i];
            }
        }
        double scaleFactor = 1.0;
        if (maxGain > 255.0) {
            scaleFactor = 255 / maxGain;
        }

        // Build histogram of 256 bins and figure out the new scaled max
        maxGain = 0;
        int gainHist[] = new int[256];
        for (int i = 0; i < numFrames; i++) {
            int smoothedGain = (int) (smoothedGains[i] * scaleFactor);
            if (smoothedGain < 0)
                smoothedGain = 0;
            if (smoothedGain > 255)
                smoothedGain = 255;

            if (smoothedGain > maxGain)
                maxGain = smoothedGain;

            gainHist[smoothedGain]++;
        }

        // Re-calibrate the min to be 5%
        double minGain = 0;
        int sum = 0;
        while (minGain < 255 && sum < numFrames / 20) {
            sum += gainHist[(int) minGain];
            minGain++;
        }

        // Re-calibrate the max to be 99%
        sum = 0;
        while (maxGain > 2 && sum < numFrames / 100) {
            sum += gainHist[(int) maxGain];
            maxGain--;
        }

        // Compute the heights
        //double[] heights = new double[numFrames];
        myLenByZoomLevel[0] = numFrames * 2;
        myLenByZoomLevel[1] = numFrames;
        myZoomFactorByZoomLevel[0] = 2.0;
        myZoomFactorByZoomLevel[1] = 1.0;
        for (int j = 2; j < 5; j++) {
            myLenByZoomLevel[j] = myLenByZoomLevel[j - 1] / 2;
            myZoomFactorByZoomLevel[j] = myZoomFactorByZoomLevel[j - 1] / 2.0;
        }
        if (numFrames > 5000) {
            myZoomLevel = 3;
        } else if (numFrames > 1000) {
            myZoomLevel = 2;
        } else if (numFrames > 300) {
            myZoomLevel = 1;
        } else {
            myZoomLevel = 0;
        }
        int myMaxPos = myLenByZoomLevel[myZoomLevel];
        double audioLength = Double.parseDouble(formatTime(myMaxPos, myZoomFactorByZoomLevel[myZoomLevel]));
        int arrayRange = (int) Math.floor((double) numFrames / audioLength);
        int arrayNum = ((int) Math.floor(audioLength));
        double[] perSecondsHeight = new double[arrayNum];
        Log.i("계산 잘 나왔는지 확인", "formatTime(myMaxPos) : " + Double.toString(audioLength) + " arrayNum : " + arrayNum);
        double range = maxGain - minGain;
        int seconds = 0;
        int count = 0;
        double sumHeight = 0.0;
        double averageHeight = 0.0;

        for (int i = 0; i < numFrames; i++) {
            if (seconds < arrayNum) {
                //Log.i("과정"," if(seconds < arrayNum) {");
                if (seconds == (arrayNum - 1)) {
                    //Log.i("과정","seconds == (arrayNum - 1)");
                    sumHeight += musicHeights[i];
                    //Log.i("과정","sumHeight += heights[i]");
                    count++;
                    //Log.i("과정","count++");
                    if (i == (numFrames - 1)) {
                        //Log.i("과정","i == (numFrames - 1)");
                        averageHeight = sumHeight / (double) count;
                        //Log.i("과정"," averageHeight = sumHeight / (double) count");
                        perSecondsHeight[seconds] = averageHeight;
                        decibels = DECIBEL_CONSTANTS * Math.log10(perSecondsHeight[seconds]);
                        mPref.putValue(Integer.toString(seconds), Double.toString(decibels), mKeyName);
                        //Log.i("평균 예상값", "perSecondsHeight[" + seconds + "] = " + averageHeight);
                        //Log.i("평균 예상값", "데시벨[" + seconds + "] = " + decibels);
                    }
                    //seconds < arrayNum
                } else {
                    if (seconds == (i / arrayRange)) {
                        //Log.i("평균 예상값"," if (seconds == (i / arrayRange))");
                        sumHeight += musicHeights[i];
                        count++;
                    } else {
                        if(count==0) {
                            averageHeight = 0;
                        } else {
                            averageHeight = sumHeight / (double) count;
                        }
                        //Log.i("평균 예상값","averageHeight = sumHeight / (double) count");
                        sumHeight = 0.0;
                        count = 0;
                        perSecondsHeight[seconds] = averageHeight;
                        decibels = DECIBEL_CONSTANTS * Math.log10(perSecondsHeight[seconds]);
                        mPref.putValue(Integer.toString(seconds), Double.toString(decibels), mKeyName);
                        //Log.i("평균 예상값", "perSecondsHeight[" + seconds + "] = " + averageHeight);
                        //Log.i("평균 예상값", "데시벨[" + seconds + "] = " + decibels);
                        seconds++;
                        sumHeight += musicHeights[i];
                        count++;
                    }
                }
            }
        }

//        for (int i = 0; i < numFrames; i++) {
//            double value = (smoothedGains[i] * scaleFactor - minGain) / range;
//            if (value < 0.0) {
//                value = 0.0;
//            }
//            if (value > 1.0) {
//                value = 1.0;
//            }
//            heights[i] = value * value;
//            Log.i("예상 음높이 값 " + Integer.toString(i), Double.toString(heights[i]));
//
//            if (seconds < arrayNum) {
//                //Log.i("과정"," if(seconds < arrayNum) {");
//                if (seconds == (arrayNum - 1)) {
//                    //Log.i("과정","seconds == (arrayNum - 1)");
//                    sumHeight += heights[i];
//                    //Log.i("과정","sumHeight += heights[i]");
//                    count++;
//                    //Log.i("과정","count++");
//                    if (i == (numFrames - 1)) {
//                        //Log.i("과정","i == (numFrames - 1)");
//                        averageHeight = sumHeight / (double) count;
//                        //Log.i("과정"," averageHeight = sumHeight / (double) count");
//                        perSecondsHeight[seconds] = averageHeight;
//                        decibels = DECIBEL_CONSTANTS * Math.log10(perSecondsHeight[seconds]);
//                        mPref.putValue(Integer.toString(seconds), Double.toString(perSecondsHeight[seconds]), mKeyName);
//                        //Log.i("평균 예상값", "perSecondsHeight[" + seconds + "] = " + averageHeight);
//                        Log.i("평균 예상값","데시벨["+seconds+"] = " + decibels);
//                    }
//                    //seconds < arrayNum
//                } else {
//                    if (seconds == (i / arrayRange)) {
//                        //Log.i("평균 예상값"," if (seconds == (i / arrayRange))");
//                        sumHeight += heights[i];
//                        count++;
//                    } else {
//                        averageHeight = sumHeight / (double) count;
//                        //Log.i("평균 예상값","averageHeight = sumHeight / (double) count");
//                        sumHeight = 0.0;
//                        count = 0;
//                        perSecondsHeight[seconds] = averageHeight;
//                        decibels = DECIBEL_CONSTANTS * Math.log10(perSecondsHeight[seconds]);
//                        mPref.putValue(Integer.toString(seconds), Double.toString(perSecondsHeight[seconds]), mKeyName);
//                        //Log.i("평균 예상값", "perSecondsHeight[" + seconds + "] = " + averageHeight);
//                        Log.i("평균 예상값","데시벨["+seconds+"] = " + decibels);
//                        seconds++;
//                        sumHeight += heights[i];
//                        count++;
//                    }
//                }
//            }
//        }
        Log.i("computeDoubles", "종료");
    }

    private String formatTime(int pixels, double myZoomFactorByZoomLevel) {

        return formatDecimal(myPixelsToSeconds(pixels, myZoomFactorByZoomLevel));
    }

    public double myPixelsToSeconds(int pixels, double myZoomFactorByZoomLevel) {
        double z = myZoomFactorByZoomLevel;
        //Log.i("pixelsToSecond 함수값", "pixels : " + Integer.toString(pixels) + " z : " + Double.toString(z));
        return (pixels * (double) mSamplesPerFrame / (mSampleRate * z));
    }


    private String formatDecimal(double x) {
        int xWhole = (int) x;
        int xFrac = (int) (100 * (x - xWhole) + 0.5);
        //Log.i("formatDecimal 함수값 1044줄", "x : " + Double.toString(x) + " xWhole : " + Integer.toString(xWhole) + " xFrac : " + Integer.toString(xFrac));
        if (xFrac >= 100) {
            xWhole++; //Round up
            xFrac -= 100; //Now we need the remainder after the round up
            //Log.i("formatDecimal 함수값 1048줄", "xWhole : " + Integer.toString(xWhole) + " xFrac : " + Integer.toString(xFrac));
            if (xFrac < 10) {
                xFrac *= 10; //we need a fraction that is 2 digits long
                //Log.i("formatDecimal 함수값 1051줄", "xFrac : " + Integer.toString(xFrac));
            }
        }

        if (xFrac < 10) {
            //Log.i("formatDecimal 함수값 1056줄", "xWhole + \".0\" + xFrac : " + xWhole + ".0" + xFrac);
            return xWhole + ".0" + xFrac;
        } else {
            //Log.i("formatDecimal 함수값 1059줄", "xWhole + \".\" + xFrac : " + xWhole + "." + xFrac);
            return xWhole + "." + xFrac;
        }
    }

}
